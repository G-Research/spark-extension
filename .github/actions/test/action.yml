name: 'Test'
author: 'EnricoMi'
description: 'A GitHub Action that tests spark-extension'

inputs:
  spark-version:
    description: Spark version, e.g. 3.4.0 or 3.4.0-SNAPSHOT
    required: true
  scala-version:
    description: Scala version, e.g. 2.12.15
    required: true
  spark-compat-version:
    description: Spark compatibility version, e.g. 3.4
    required: true
  scala-compat-version:
    description: Scala compatibility version, e.g. 2.12
    required: true

runs:
  using: 'composite'
  steps:
  - name: Set versions in pom.xml
    run: |
      ./set-version.sh ${{ inputs.spark-version }} ${{ inputs.scala-version }}
      git diff
    shell: bash

  - name: Fetch Binaries Artifact
    uses: actions/download-artifact@v3
    with:
      name: Binaries-${{ inputs.spark-version }}-${{ inputs.scala-version }}
      path: .

  - name: Cache Maven packages
    uses: actions/cache@v3
    with:
      path: ~/.m2/repository
      key: ${{ runner.os }}-mvn-build-${{ inputs.spark-version }}-${{ inputs.scala-version }}-${{ hashFiles('pom.xml') }}

  - name: Setup JDK 1.8
    uses: actions/setup-java@v3
    with:
      java-version: '8'
      distribution: 'zulu'

  - name: Cache Pip packages
    # pyspark is not available for snapshots or scala other than 2.12
    # we would have to compile spark from sources for this, not worth it
    if: inputs.scala-compat-version == '2.12' && ! contains(inputs.spark-version, 'SNAPSHOT')
    uses: actions/cache@v3
    with:
      path: ~/.cache/pip
      key: ${{ runner.os }}-pip-test-${{ inputs.python-version }}-${{ hashFiles('requirements.txt') }}

  - name: Setup Python
    # pyspark is not available for snapshots or scala other than 2.12
    # we would have to compile spark from sources for this, not worth it
    if: inputs.scala-compat-version == '2.12' && ! contains(inputs.spark-version, 'SNAPSHOT')
    uses: actions/setup-python@v4
    with:
      python-version: ${{ inputs.python-version }}

  - name: Install Python dependencies
    # pyspark is not available for snapshots or scala other than 2.12
    # we would have to compile spark from sources for this, not worth it
    if: inputs.scala-compat-version == '2.12' && ! contains(inputs.spark-version, 'SNAPSHOT')
    run: |
      python -m pip install --upgrade pip
      pip install pypandoc
      pip install -r python/requirements-${{ inputs.spark-compat-version }}_${{ inputs.scala-compat-version }}.txt
      pip install pytest
    shell: bash

  - name: Scala and Java Tests
    run: mvn --batch-mode test
    shell: bash

  - name: Python Tests
    # pyspark is not available for snapshots or scala other than 2.12
    # we would have to compile spark from sources for this, not worth it
    if: inputs.scala-compat-version == '2.12' && ! contains(inputs.spark-version, 'SNAPSHOT')
    env:
      PYTHONPATH: python:python/test
    run: |
      mkdir -p target/surefire-reports
      python -m pytest python/test --junit-xml target/surefire-reports/pytest.xml
    shell: bash

  - name: Generate Unit Test Report
    if: failure()
    run: mvn --batch-mode surefire-report:report-only
    shell: bash

  - name: Upload Unit Test Results
    if: always()
    uses: actions/upload-artifact@v3
    with:
      name: Unit Test Results (Spark ${{ inputs.spark-version }} Scala ${{ inputs.scala-version }} Python ${{ inputs.python-version }})
      path: |
        target/surefire-reports/*.xml
        !target/surefire-reports/TEST-org.scalatest*.xml
        target/site/surefire-report.html

branding:
  icon: 'check-circle'
  color: 'green'
