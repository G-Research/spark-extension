name: 'Test Python'
author: 'EnricoMi'
description: 'A GitHub Action that tests Python spark-extension'

# pyspark is not available for snapshots or scala other than 2.12
# we would have to compile spark from sources for this, not worth it
# so this action only works with scala 2.12 and non-snapshot spark versions
inputs:
  spark-version:
    description: Spark version, e.g. 3.4.0
    required: true
  scala-version:
    description: Scala version, e.g. 2.12.15
    required: true
  spark-compat-version:
    description: Spark compatibility version, e.g. 3.4
    required: true
  scala-compat-version:
    description: Scala compatibility version, e.g. 2.12
    required: true
  python-version:
    description: Python version, e.g. 3.8
    required: true

runs:
  using: 'composite'
  steps:
  - name: Set versions in pom.xml
    run: |
      ./set-version.sh ${{ inputs.spark-version }} ${{ inputs.scala-version }}
      git diff

      SPARK_EXTENSION_VERSION=$(grep --max-count=1 "<version>.*</version>" pom.xml | sed -E -e "s/\s*<[^>]+>//g")
      echo "SPARK_EXTENSION_VERSION=$SPARK_EXTENSION_VERSION" | tee -a "$GITHUB_ENV"
    shell: bash

  - name: Fetch Binaries Artifact
    uses: actions/download-artifact@v4
    with:
      name: Binaries-${{ inputs.spark-compat-version }}-${{ inputs.scala-compat-version }}
      path: .

  - name: Cache Maven packages
    if: github.event_name != 'merge_group'
    uses: actions/cache@v3
    with:
      path: ~/.m2/repository
      key: ${{ runner.os }}-mvn-build-${{ inputs.spark-version }}-${{ inputs.scala-version }}-${{ hashFiles('pom.xml') }}
      restore-keys: ${{ runner.os }}-mvn-build-${{ inputs.spark-version }}-${{ inputs.scala-version }}-

  - name: Setup JDK 1.8
    uses: actions/setup-java@v4
    with:
      java-version: '8'
      distribution: 'zulu'

  - name: Cache Pip packages
    if: github.event_name != 'merge_group'
    uses: actions/cache@v3
    with:
      path: ~/.cache/pip
      key: ${{ runner.os }}-pip-test-${{ inputs.python-version }}-${{ hashFiles(format('python/requirements-{0}_{1}.txt', inputs.spark-compat-version, inputs.scala-compat-version)) }}
      restore-keys: ${{ runner.os }}-pip-test-${{ inputs.python-version }}-

  - name: Setup Python
    uses: actions/setup-python@v5
    with:
      python-version: ${{ inputs.python-version }}

  - name: Install Python dependencies
    run: |
      python -m pip install --upgrade pip
      pip install pypandoc
      pip install -r python/requirements-${{ inputs.spark-compat-version }}_${{ inputs.scala-compat-version }}.txt
      pip install -r python/test/requirements.txt

      SPARK_HOME=$(python -c "import pyspark; import os; print(os.path.dirname(pyspark.__file__))")
      echo "SPARK_HOME=$SPARK_HOME" | tee -a "$GITHUB_ENV"
    shell: bash

  - name: Prepare poetry tests
    run: |
      # install poetry in venv
      python -m venv .poetry-venv
      .poetry-venv/bin/python -m pip install poetry
      # env var needed by poetry tests
      echo "POETRY_PYTHON=$PWD/.poetry-venv/bin/python" | tee -a "$GITHUB_ENV"

      # clone example poetry project
      git clone https://github.com/Textualize/rich.git .rich
      cd .rich
      git reset --hard 20024635c06c22879fd2fd1e380ec4cccd9935dd
      # env var needed by poetry tests
      echo "RICH_SOURCES=$PWD" | tee -a "$GITHUB_ENV"
    shell: bash

  - name: Python Unit Tests
    env:
      PYTHONPATH: python:python/test
    run: |
      python -m pytest python/test --junit-xml test-results/pytest-$(date +%s.%N)-$RANDOM.xml
    shell: bash

  - name: Install Spark Extension
    run: mvn --batch-mode --update-snapshots install -Dspotless.check.skip -DskipTests -Dmaven.test.skip=true -Dgpg.skip
    shell: bash

  - name: Python Integration Tests
    env:
      PYTHONPATH: python:python/test
    run: |
      find python/test -name 'test*.py' > tests
      while read test
      do
        if ! $SPARK_HOME/bin/spark-submit --master "local[2]" --packages uk.co.gresearch.spark:spark-extension_${{ inputs.scala-compat-version }}:$SPARK_EXTENSION_VERSION "$test" test-results
        then
          state="fail"
        fi
      done < tests
      if [[ "$state" == "fail" ]]; then exit 1; fi
    shell: bash

  - name: Python Release Test
    run: |
      $SPARK_HOME/bin/spark-submit --packages uk.co.gresearch.spark:spark-extension_${{ inputs.scala-compat-version }}:$SPARK_EXTENSION_VERSION test-release.py
    shell: bash

  - name: Scala Release Test
    run: |
      $SPARK_HOME/bin/spark-shell --packages uk.co.gresearch.spark:spark-extension_${{ inputs.scala-compat-version }}:$SPARK_EXTENSION_VERSION < test-release.scala
    shell: bash

  - name: Upload Test Results
    if: always()
    uses: actions/upload-artifact@v4
    with:
      name: Python Test Results (Spark ${{ inputs.spark-version }} Scala ${{ inputs.scala-version }} Python ${{ inputs.python-version }})
      path: test-results/*.xml

branding:
  icon: 'check-circle'
  color: 'green'
